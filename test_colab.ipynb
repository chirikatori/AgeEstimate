{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Install required libraries\n",
    "!pip install -q mne mne_features coffeine\n",
    "\n",
    "# Import necessary modules\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from mne_features.feature_extraction import extract_features\n",
    "import coffeine\n",
    "\n",
    "# Define constants and paths in your drive\n",
    "# download data follow link : https://drive.google.com/drive/folders/1E413wShdFcObBw1RNARfU6XLbkLEdYKR?fbclid=IwZXh0bgNhZW0CMTEAAR0mz9ITt4nSBTDargQtlsL9Q0SrHMcdOj24P30icNSBNwy_G2yJ3lNn6UY_aem_auDILAvD02L0RP20dp5X4g\n",
    "RAW_DATA_FOLDER = \"/content/drive/MyDrive/all_group/\"\n",
    "\n",
    "METADATA_FILE = os.path.join(RAW_DATA_FOLDER, \"filtered_subjects_with_age.tsv\")\n",
    "N_ROWS = 100  # Number of rows to load from metadata\n",
    "\n",
    "# Load metadata\n",
    "metadata = pd.read_csv(METADATA_FILE, sep=\"\\t\", nrows=N_ROWS)\n",
    "metadata.columns = [col.strip() for col in metadata.columns]  # Clean column names\n",
    "file_paths = [os.path.join(RAW_DATA_FOLDER, f\"{participant_id}_sflip_parc-raw.fif\") for participant_id in metadata[\"participant_id\"]]\n",
    "\n",
    "# Load raw data and pick 'misc' channel\n",
    "data_raw = [mne.io.read_raw_fif(path, preload=True, verbose=False).pick('misc') for path in tqdm(file_paths, desc=\"Loading Data\")]\n",
    "for raw in data_raw:\n",
    "    raw.set_channel_types({ch_name: 'eeg' for ch_name in raw.info['ch_names'] if 'misc' in ch_name})\n",
    "channel = data_raw[0].info['ch_names']\n",
    "for r in data_raw:\n",
    "    r.pick(channel)\n",
    "\n",
    "# Create 2-second epochs\n",
    "events = mne.make_fixed_length_events(\n",
    "    data_raw[0], start=2, duration=2 - 1 / data_raw[0].info['sfreq'], overlap=0., stop=100\n",
    ")\n",
    "data_epoch = [mne.Epochs(raw, events=events, event_id=1, tmin=0, tmax=2, proj=False, baseline=None, preload=True) for raw in data_raw]\n",
    "\n",
    "# Filter valid epochs\n",
    "valid_data_epoch = [epoch for epoch in data_epoch if epoch is not None and len(epoch) > 0]\n",
    "invalid_indices = [i for i, epoch in enumerate(data_epoch) if epoch is None or len(epoch) == 0]\n",
    "print(f\"Removed epochs at indices: {invalid_indices}\")\n",
    "print(f\"Remaining valid epochs: {len(valid_data_epoch)}\")\n",
    "\n",
    "# Feature extraction parameters\n",
    "# HC_SELECTED_FUNCS = [\n",
    "#     'std', 'kurtosis', 'skewness', 'quantile', 'ptp_amp', 'mean', 'pow_freq_bands',\n",
    "#     'spect_entropy', 'app_entropy', 'samp_entropy', 'svd_entropy', 'hurst_exp',\n",
    "#     'hjorth_complexity', 'hjorth_mobility', 'line_length', 'wavelet_coef_energy',\n",
    "#     'higuchi_fd', 'zero_crossings', 'svd_fisher_info'\n",
    "# ]\n",
    "# HC_FUNC_PARAMS = {\n",
    "#     'quantile__q': [0.1, 0.25, 0.75, 0.9],\n",
    "#     'pow_freq_bands__freq_bands': [0, 2, 4, 8, 13, 18, 24, 30, 49],\n",
    "#     'pow_freq_bands__ratios': 'all',\n",
    "#     'pow_freq_bands__ratios_triu': True,\n",
    "#     'pow_freq_bands__log': True,\n",
    "#     'pow_freq_bands__normalize': None\n",
    "# }\n",
    "\n",
    "# # Extract features from epochs\n",
    "# final_features = [\n",
    "#     extract_features(\n",
    "#         epoch.get_data(), epoch.info['sfreq'], HC_SELECTED_FUNCS,\n",
    "#         funcs_params=HC_FUNC_PARAMS, n_jobs=-1, ch_names=epoch.ch_names\n",
    "#     ) for epoch in tqdm(valid_data_epoch, desc=\"Extracting Features\")\n",
    "# ]\n",
    "\n",
    "# Define frequency bands for coffeine\n",
    "FREQUENCY_BANDS = {\n",
    "    \"low\": (0.1, 1),\n",
    "    \"delta\": (1, 4),\n",
    "    \"theta\": (4, 8),\n",
    "    \"alpha\": (8, 15),\n",
    "    \"beta_low\": (15, 26),\n",
    "    \"beta_mid\": (26, 35),\n",
    "    \"beta_high\": (35, 49)\n",
    "}\n",
    "\n",
    "def extract_fb_covs(epochs, n_jobs=4):\n",
    "    features, meta_info = coffeine.compute_features(\n",
    "        epochs, features=('covs',), n_fft=1024, n_overlap=512,\n",
    "        fs=epochs.info['sfreq'], fmax=49, frequency_bands=FREQUENCY_BANDS, n_jobs=n_jobs\n",
    "    )\n",
    "    features['meta_info'] = meta_info\n",
    "    return features\n",
    "\n",
    "# Compute frequency band covariance features\n",
    "data_train = [\n",
    "    extract_fb_covs(epoch.set_channel_types({ch_name: 'eeg' for ch_name in channel}), n_jobs=4) for epoch in tqdm(valid_data_epoch, desc=\"Computing Frequency Band Covariances\")\n",
    "]\n",
    "covs = np.array([sub['covs'] for sub in data_train])\n",
    "X = pd.DataFrame({band: list(covs[:, ii]) for ii, band in enumerate(FREQUENCY_BANDS)})\n",
    "\n",
    "# Prepare training and validation datasets\n",
    "train_size = int(len(X) * 0.75)\n",
    "X_train, X_valid = X[:train_size], X[train_size:]\n",
    "y_train = [age for i, age in enumerate(metadata[\"age\"]) if i not in invalid_indices]\n",
    "y_train = y_train[:len(X)]\n",
    "y_train, y_valid = y_train[:train_size], y_train[train_size:]\n",
    "\n",
    "# Train Ridge regression model\n",
    "filter_bank_transformer = coffeine.make_filter_bank_transformer(\n",
    "    names=list(FREQUENCY_BANDS), method='riemann',\n",
    "    projection_params=dict(scale='auto', n_compo=len(channel) - 1)\n",
    ")\n",
    "model = make_pipeline(\n",
    "    filter_bank_transformer, StandardScaler(),\n",
    "    RidgeCV(alphas=np.logspace(-5, 10, 100))\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_predictions = model.predict(X_train)\n",
    "valid_predictions = model.predict(X_valid)\n",
    "print(f\"Train R2: {r2_score(y_train, train_predictions)}\")\n",
    "print(f\"Train MAE: {mean_absolute_error(y_train, train_predictions)}\")\n",
    "print(f\"Validation R2: {r2_score(y_valid, valid_predictions)}\")\n",
    "print(f\"Validation MAE: {mean_absolute_error(y_valid, valid_predictions)}\")\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Train set\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_train, train_predictions, alpha=0.7, label=\"Predictions\")\n",
    "plt.plot([min(y_train), max(y_train)], [min(y_train), max(y_train)], 'r--', label=\"Ideal\")\n",
    "plt.title(\"Train Set: Ground Truth vs Predictions\")\n",
    "plt.xlabel(\"Ground Truth (y_train)\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Validation set\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_valid, valid_predictions, alpha=0.7, label=\"Predictions\")\n",
    "plt.plot([min(y_valid), max(y_valid)], [min(y_valid), max(y_valid)], 'r--', label=\"Ideal\")\n",
    "plt.title(\"Validation Set: Ground Truth vs Predictions\")\n",
    "plt.xlabel(\"Ground Truth (y_valid)\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"ground_truth_vs_predictions.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
